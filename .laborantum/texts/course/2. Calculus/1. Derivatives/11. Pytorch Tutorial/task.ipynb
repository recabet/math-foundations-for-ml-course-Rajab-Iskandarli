{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "import json_tricks"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Torch\n",
                "\n",
                "Torch is the main tool for deep learning. Its power is calculating analytical derivatives through insanely complicated graph using the algorithm that is called *backpropagation*\n",
                "\n",
                "In this small tutorial we will learn to use it\n",
                "\n",
                "Below is the code that creates a computational graph of a rather complex function:\n",
                "\n",
                "$\\sum_{k=1}^{100} \\exp(\\sin^2(x) + x ^ 2)$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = torch.linspace(-1, 1, 100, requires_grad=True)\n",
                "y = torch.sin(x)\n",
                "\n",
                "f = torch.exp(y ** 2 + x ** 2).sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, as we have a value of the function, we can call `.backward()` on the single-valued tensor.\n",
                "\n",
                "This tensor holds the history of how was it created from the variables that require gradient calculation.\n",
                "\n",
                "In our setup, `x` is such a set of variables\n",
                "\n",
                "Before we run `.backward()`, the gradients are empty:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "None\n"
                    ]
                }
            ],
            "source": [
                "print(x.grad)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let us run `.backward()` and see, what happens:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([-16.0544, -15.0151, -14.0417, -13.1303, -12.2771, -11.4785, -10.7310,\n",
                        "        -10.0316,  -9.3772,  -8.7650,  -8.1922,  -7.6564,  -7.1551,  -6.6862,\n",
                        "         -6.2474,  -5.8369,  -5.4527,  -5.0931,  -4.7565,  -4.4412,  -4.1459,\n",
                        "         -3.8691,  -3.6096,  -3.3662,  -3.1377,  -2.9231,  -2.7214,  -2.5316,\n",
                        "         -2.3529,  -2.1844,  -2.0255,  -1.8752,  -1.7331,  -1.5983,  -1.4704,\n",
                        "         -1.3487,  -1.2327,  -1.1219,  -1.0158,  -0.9140,  -0.8159,  -0.7213,\n",
                        "         -0.6296,  -0.5405,  -0.4537,  -0.3687,  -0.2852,  -0.2029,  -0.1214,\n",
                        "         -0.0404,   0.0404,   0.1214,   0.2029,   0.2852,   0.3687,   0.4537,\n",
                        "          0.5405,   0.6296,   0.7213,   0.8159,   0.9140,   1.0158,   1.1219,\n",
                        "          1.2327,   1.3487,   1.4704,   1.5983,   1.7331,   1.8752,   2.0255,\n",
                        "          2.1844,   2.3529,   2.5316,   2.7214,   2.9231,   3.1377,   3.3662,\n",
                        "          3.6096,   3.8691,   4.1459,   4.4412,   4.7565,   5.0931,   5.4527,\n",
                        "          5.8369,   6.2474,   6.6862,   7.1551,   7.6564,   8.1922,   8.7650,\n",
                        "          9.3772,  10.0316,  10.7310,  11.4785,  12.2771,  13.1303,  14.0417,\n",
                        "         15.0151,  16.0544])\n"
                    ]
                }
            ],
            "source": [
                "f.backward()\n",
                "\n",
                "print(x.grad)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now you can calculate gradients through the graphs of any complexity"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'{\"__ndarray__\": [-16.054431915283203, -15.015067100524902, -14.041696548461914, -13.130295753479004, -12.27707576751709, -11.478453636169434, -10.731040000915527, -10.03164291381836, -9.377245903015137, -8.765003204345703, -8.192231178283691, -7.656403541564941, -7.1551361083984375, -6.686185836791992, -6.247439861297607, -5.836910724639893, -5.452730178833008, -5.0931396484375, -4.756486892700195, -4.441222667694092, -4.145886421203613, -3.869112014770508, -3.6096153259277344, -3.366189479827881, -3.1377041339874268, -2.923098564147949, -2.7213759422302246, -2.531602621078491, -2.352900505065918, -2.1844468116760254, -2.025467872619629, -1.8752362728118896, -1.7330691814422607, -1.5983225107192993, -1.470389723777771, -1.3486993312835693, -1.232710361480713, -1.1219115257263184, -1.0158181190490723, -0.9139689207077026, -0.8159250020980835, -0.7212665677070618, -0.6295921802520752, -0.5405148267745972, -0.45366185903549194, -0.3686716556549072, -0.28519248962402344, -0.20288044214248657, -0.12139774858951569, -0.04041091352701187, 0.04041091352701187, 0.12139774858951569, 0.20288044214248657, 0.28519248962402344, 0.3686716556549072, 0.45366185903549194, 0.5405148267745972, 0.6295921802520752, 0.7212665677070618, 0.8159250020980835, 0.9139689207077026, 1.0158181190490723, 1.1219115257263184, 1.232710361480713, 1.3486993312835693, 1.470389723777771, 1.5983225107192993, 1.7330691814422607, 1.8752362728118896, 2.025467872619629, 2.1844468116760254, 2.352900505065918, 2.531602621078491, 2.7213759422302246, 2.923098564147949, 3.1377041339874268, 3.366189479827881, 3.6096153259277344, 3.869112014770508, 4.145886421203613, 4.441222667694092, 4.756486892700195, 5.0931396484375, 5.452730178833008, 5.836910724639893, 6.247439861297607, 6.686185836791992, 7.1551361083984375, 7.656403541564941, 8.192231178283691, 8.765003204345703, 9.377245903015137, 10.03164291381836, 10.731040000915527, 11.478453636169434, 12.27707576751709, 13.130295753479004, 14.041696548461914, 15.015067100524902, 16.054431915283203], \"dtype\": \"float32\", \"shape\": [100]}'"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "json_tricks.dump(x.grad.numpy(), '.answer.json')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
